{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Qeec01hbb1Is"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nengo\n",
        "import nengo_dl\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#sources:\n",
        "#https://www.kaggle.com/code/vtu5118/cifar-10-using-vgg16\n",
        "#https://towardsdatascience.com/creating-vgg-from-scratch-using-tensorflow-a998a5640155"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "id": "3wvUGsdHyeJs",
        "outputId": "b883ac3c-9d1a-4477-ecff-a5c3939c68f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " hidden1 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " hidden2 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,111,242\n",
            "Trainable params: 15,111,242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vgg16_model = tf.keras.applications.vgg16.VGG16(weights='imagenet',\n",
        "                    include_top=False,\n",
        "                    classes=10,\n",
        "                    input_shape=(32,32,3)# input: 32x32 images with 3 channels -> (32, 32, 3) tensors.\n",
        "                   )\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Add vgg16 layers\n",
        "for layer in vgg16_model.layers:\n",
        "    model.add(layer)\n",
        "\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu', name='hidden1'))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu', name='hidden2'))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax', name='predictions'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpL5gw_yycfa"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pxpwFCsqcbXb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load CIFAR10 data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# One hot encode labels\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Data normalization\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train  /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgE6iNj2rxQD",
        "outputId": "51e835eb-71aa-4957-ebdc-14f3aacaea33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 10)\n",
            "(40000, 32, 32, 3)\n",
            "(40000, 10)\n"
          ]
        }
      ],
      "source": [
        "# Shuffle data before splitting into validation set\n",
        "\n",
        "p = np.random.permutation(len(x_train))\n",
        "print(x_train.shape)\n",
        "x_train, y_train = x_train[p], y_train[p]\n",
        "print(x_train.shape)\n",
        "\n",
        "# 20% validation, 80% training\n",
        "val_split = 0.2\n",
        "num_val = int(val_split * len(x_train))\n",
        "\n",
        "# Split into train, validation, and test sets\n",
        "x_val = x_train[:num_val]\n",
        "y_val = y_train[:num_val]\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)\n",
        "\n",
        "x_train = x_train[num_val:]\n",
        "y_train = y_train[num_val:]\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xqsdX0-qjfbY"
      },
      "outputs": [],
      "source": [
        "# For saving model weights\n",
        "checkpoint_path = \"training/vgg16.weights.h5\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBDuaQb9cx_H",
        "outputId": "55bd2d77-5842-461b-e2d2-7c5a2d8d5e28"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
        "batch_size = 128\n",
        "epochs = 100\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    # optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=[\n",
        "        'accuracy'\n",
        "    ]\n",
        ")\n",
        "\n",
        "def lr_scheduler(epoch):\n",
        "    return 0.001 * (0.5 ** (epoch // 20))\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "aug = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\")\n",
        "\n",
        "# model.fit(aug.flow(x_train,y_train, batch_size=batch_size),\n",
        "#           batch_size=batch_size,\n",
        "#           epochs=epochs,\n",
        "#           callbacks=[reduce_lr, cp_callback],\n",
        "#           validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnK3eAfxiHNX",
        "outputId": "c0bebfef-a10b-405e-f10e-ff6b6ed758c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 20s 63ms/step - loss: 0.4016 - accuracy: 0.8821\n",
            "Test Acc: 88.21%, Test Loss:  0.40\n"
          ]
        }
      ],
      "source": [
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(\"Test Acc: {:5.2f}%, Test Loss: {:5.2f}\".format(100 * acc, loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 153600000 into shape (50000,1,32,32)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_time_dimension\u001b[39m(arr):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mreshape(arr, (arr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, arr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], arr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m----> 5\u001b[0m X_train_t \u001b[38;5;241m=\u001b[39m \u001b[43madd_time_dimension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m Y_train_t \u001b[38;5;241m=\u001b[39m add_time_dimension(y_train)\n\u001b[0;32m      7\u001b[0m X_val_t \u001b[38;5;241m=\u001b[39m add_time_dimension(x_val)\n",
            "Cell \u001b[1;32mIn[21], line 3\u001b[0m, in \u001b[0;36madd_time_dimension\u001b[1;34m(arr)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_time_dimension\u001b[39m(arr):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[1;32md:\\Folders\\Programming\\snn-research\\vgg16-snn\\.env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Folders\\Programming\\snn-research\\vgg16-snn\\.env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
            "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 153600000 into shape (50000,1,32,32)"
          ]
        }
      ],
      "source": [
        "# Add time dimension to data for SNN\n",
        "def add_time_dimension(arr):\n",
        "    return np.reshape(arr, (arr.shape[0], 1, -1))\n",
        "\n",
        "X_train_t = add_time_dimension(x_train)\n",
        "Y_train_t = add_time_dimension(y_train)\n",
        "X_val_t = add_time_dimension(x_val)\n",
        "Y_val_t = add_time_dimension(y_val)\n",
        "X_test_t = add_time_dimension(x_test)\n",
        "Y_test_t = add_time_dimension(y_test)\n",
        "\n",
        "print(X_train_t.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Folders\\Programming\\snn-research\\vgg16-snn\\.env\\lib\\site-packages\\nengo_dl\\converter.py:920: UserWarning: Converting sequential model to functional model; use `Converter.model` to refer to the functional model (rather than the original sequential model) when working with the output of the Converter\n",
            "  warnings.warn(\n",
            "d:\\Folders\\Programming\\snn-research\\vgg16-snn\\.env\\lib\\site-packages\\nengo_dl\\converter.py:324: UserWarning: Cannot convert max pooling layers to native Nengo objects; consider setting max_to_avg_pool=True to use average pooling instead. Falling back to TensorNode.\n",
            "  warnings.warn(\n",
            "d:\\Folders\\Programming\\snn-research\\vgg16-snn\\.env\\lib\\site-packages\\nengo_dl\\converter.py:324: UserWarning: Layer type Dropout does not have a registered converter. Falling back to TensorNode.\n",
            "  warnings.warn(\n",
            "d:\\Folders\\Programming\\snn-research\\vgg16-snn\\.env\\lib\\site-packages\\nengo_dl\\converter.py:583: UserWarning: Activation type <function softmax at 0x000002317FC37250> does not have a native Nengo equivalent; falling back to a TensorNode\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Begin SNN conversion\n",
        "ndl_model = nengo_dl.Converter(\n",
        "    model,\n",
        "    swap_activations={\n",
        "        tf.keras.activations.relu: nengo.SpikingRectifiedLinear()\n",
        "    },\n",
        "    scale_firing_rates=20,\n",
        "    synapse=0.005,\n",
        "    inference_only=True\n",
        ")\n",
        "\n",
        "# Train model\n",
        "# with nengo_dl.Simulator(converter.net, minibatch_size=batch_size) as sim:\n",
        "#     # run training\n",
        "#     sim.compile(\n",
        "#         optimizer=optimizer,\n",
        "#         loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
        "#         metrics=[tf.metrics.sparse_categorical_accuracy],\n",
        "#     )\n",
        "\n",
        "#     converted_inp = converter.inputs[model.input]\n",
        "#     converted_dense = converter.outputs[model.output]\n",
        "\n",
        "#     sim.fit(\n",
        "#         {converted_inp: X_train_t},\n",
        "#         {converted_dense: Y_train_t},\n",
        "#         validation_data=(\n",
        "#             {converted_inp: X_val_t},\n",
        "#             {converted_dense: Y_val_t}\n",
        "#         ),\n",
        "#         callbacks=[reduce_lr],\n",
        "#         epochs=epochs\n",
        "#     )\n",
        "\n",
        "#     # save the parameters to file\n",
        "#     sim.save_params(\"./training/keras_to_snn_params\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "(<Reference wrapping <KerasTensor: shape=(None, 32, 32, 3) dtype=float32 (created by layer 'reshape')>>,)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[28], line 31\u001b[0m\n\u001b[0;32m     26\u001b[0m                             \u001b[38;5;66;03m# class-probabilities output of the model.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m test_batches \u001b[38;5;241m=\u001b[39m get_nengo_compatible_test_data_generator(\n\u001b[0;32m     29\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size, n_steps \u001b[38;5;241m=\u001b[39m n_steps)\n\u001b[1;32m---> 31\u001b[0m ndl_mdl_inpt \u001b[38;5;241m=\u001b[39m \u001b[43mndl_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# Input layer is Layer 0.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m ndl_mdl_otpt \u001b[38;5;241m=\u001b[39m ndl_model\u001b[38;5;241m.\u001b[39moutputs[model\u001b[38;5;241m.\u001b[39moutput] \u001b[38;5;66;03m# Output layer is last.\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Run the simulation.\u001b[39;00m\n",
            "File \u001b[1;32md:\\Folders\\Programming\\snn-research\\vgg16-snn\\.env\\lib\\site-packages\\nengo_dl\\converter.py:398\u001b[0m, in \u001b[0;36mConverter.KerasTensorDict.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
            "\u001b[1;31mKeyError\u001b[0m: (<Reference wrapping <KerasTensor: shape=(None, 32, 32, 3) dtype=float32 (created by layer 'reshape')>>,)"
          ]
        }
      ],
      "source": [
        "# Source: https://r-gaurav.github.io/2021/03/07/Spiking-Neural-Nets-for-Image-Classification-in-Nengo-DL.html\n",
        "# Tile the test images.\n",
        "def get_nengo_compatible_test_data_generator(batch_size=100, n_steps=30):\n",
        "  \"\"\"\n",
        "  Returns a test data generator of tiled (i.e. repeated) images.\n",
        "\n",
        "  Args:\n",
        "    batch_size <int>: Number of data elements in each batch.\n",
        "    n_steps <int>: Number of timesteps for which the test data has to\n",
        "                   be repeated.\n",
        "  \"\"\"\n",
        "  num_images = x_test.shape[0]\n",
        "  # Flatten the images\n",
        "  reshaped_x_test = x_test.reshape((num_images, 1, -1))\n",
        "  # Tile/Repeat them for `n_steps` times.\n",
        "  tiled_x_test = np.tile(reshaped_x_test, (1, n_steps, 1))\n",
        "\n",
        "  for i in range(0, num_images, batch_size):\n",
        "    yield (tiled_x_test[i:i+batch_size], y_test[i:i+batch_size])\n",
        "\n",
        "n_steps = 30 # Number of timesteps\n",
        "collect_spikes_output = True\n",
        "ndl_mdl_spikes = [] # To store the spike outputs of the first Conv layer and the\n",
        "                    # penultimate dense layer whose probes we defined earlier.\n",
        "ndl_mdl_otpt_cls_probs = [] # To store the true class labels and the temporal\n",
        "                            # class-probabilities output of the model.\n",
        "\n",
        "test_batches = get_nengo_compatible_test_data_generator(\n",
        "    batch_size=batch_size, n_steps = n_steps)\n",
        "\n",
        "ndl_mdl_inpt = ndl_model.inputs[model.input] # Input layer is Layer 0.\n",
        "ndl_mdl_otpt = ndl_model.outputs[model.output] # Output layer is last.\n",
        "\n",
        "# Run the simulation.\n",
        "with nengo_dl.Simulator(ndl_model.net, minibatch_size=batch_size) as sim:\n",
        "  # Predict on each batch.\n",
        "  for batch in test_batches:\n",
        "    sim_data = sim.predict_on_batch({ndl_mdl_inpt: batch[0]})\n",
        "    for y_true, y_pred in zip(batch[1], sim_data[ndl_mdl_otpt]):\n",
        "      # Note that y_true is an array of shape (10,) and y_pred is a matrix of\n",
        "      # shape (n_steps, 10) where 10 is the number of classes in CIFAR-10 dataset.\n",
        "      ndl_mdl_otpt_cls_probs.append((y_true, y_pred))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
